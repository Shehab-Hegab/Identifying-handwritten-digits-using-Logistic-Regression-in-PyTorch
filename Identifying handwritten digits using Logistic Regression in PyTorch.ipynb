{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mAWvOxynvaTC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the torch.nn module contains the code required for the model, torchvision.datasets contain the MNIST dataset. It contains the dataset of handwritten digits that we shall be using here. The torchvision.transforms module contains various methods to transform objects into others. Here, we shall be using it to transform from images to PyTorch tensors. Also, the torch.autograd module contains the Variable class amongst others, which will be used by us while defining our tensors.\n",
        "Next, we shall download and load the dataset to memory."
      ],
      "metadata": {
        "id": "tHfsYFqexCoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the batch size\n",
        "batch_size = 64\n",
        "\n",
        "# MNIST Dataset (Images and Labels)\n",
        "train_dataset = dsets.MNIST(root ='./data',\n",
        "                            train = True,\n",
        "                            transform = transforms.ToTensor(),\n",
        "                            download = True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root ='./data',\n",
        "                           train = False,\n",
        "                           transform = transforms.ToTensor())\n",
        "\n",
        "# Dataset Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False)\n",
        "\n",
        "# This code is modified by Susobhan Akhuli\n"
      ],
      "metadata": {
        "id": "RSQLpohGwjL9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we shall define our hyperparameters."
      ],
      "metadata": {
        "id": "GtZfXsR9ycRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper Parameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n"
      ],
      "metadata": {
        "id": "Hd70ihoMyYwa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our dataset, the image size is 28*28. Thus, our input size is 784. Also, 10 digits are present in this and hence, we can have 10 different outputs. Thus, we set num_classes as 10. Also, we shall train five times on the entire dataset. Finally, we will train in small batches of 100 images each so as to prevent the crashing of the program due to memory overflow.\n",
        "After this, we shall be defining our model as below. Here, we shall initialize our model as a subclass of torch.nn.Module and then define the forward pass. In the code that we are writing, the softmax is internally calculated during each forward pass and hence we do not need to specify it inside the forward() function."
      ],
      "metadata": {
        "id": "Nb0l0GqrzZne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "4aVK-Je2yq7i"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having defined our class, now we instantiate an object for the same."
      ],
      "metadata": {
        "id": "QlEV4YjD0ShQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(input_size, num_classes)\n"
      ],
      "metadata": {
        "id": "LH6PlSR60E-z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we set our loss function and the optimizer. Here, we shall be using the cross-entropy loss and for the optimizer, we shall be using the stochastic gradient descent algorithm with a learning rate of 0.001 as defined in the hyperparameter above."
      ],
      "metadata": {
        "id": "GvbzXB3G0fd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n"
      ],
      "metadata": {
        "id": "qRCKtvTT0YWD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we shall start the training.\n",
        "\n",
        "Here, we shall be performing the following tasks:\n",
        "\n",
        "Reset all gradients to 0.\n",
        "\n",
        "Make a forward pass.\n",
        "\n",
        "Calculate the loss.\n",
        "\n",
        "Perform backpropagation.\n",
        "\n",
        "Update all weights."
      ],
      "metadata": {
        "id": "lZkSZEdv07du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = Variable(images.view(-1, 28 * 28))\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "                % (epoch + 1, num_epochs, i + 1,\n",
        "                    len(train_dataset) // batch_size, loss.item())) # Use loss.item() to get the scalar value\n",
        "\n",
        "# This code is modified by Susobhan Akhuli\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLBb7lS90s-D",
        "outputId": "d5e9a0f6-361f-4cfc-ec8e-9cc0c6bb9350"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.2178\n",
            "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.0835\n",
            "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 2.0259\n",
            "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9683\n",
            "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.8618\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.7298\n",
            "Epoch: [ 1/ 5], Step: [ 700/ 600], Loss: 1.7862\n",
            "Epoch: [ 1/ 5], Step: [ 800/ 600], Loss: 1.6211\n",
            "Epoch: [ 1/ 5], Step: [ 900/ 600], Loss: 1.5724\n",
            "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.5245\n",
            "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.5908\n",
            "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.4475\n",
            "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.5040\n",
            "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.3032\n",
            "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.4328\n",
            "Epoch: [ 2/ 5], Step: [ 700/ 600], Loss: 1.2689\n",
            "Epoch: [ 2/ 5], Step: [ 800/ 600], Loss: 1.2780\n",
            "Epoch: [ 2/ 5], Step: [ 900/ 600], Loss: 1.2777\n",
            "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.1525\n",
            "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.2039\n",
            "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3138\n",
            "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.1148\n",
            "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.1847\n",
            "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 0.9900\n",
            "Epoch: [ 3/ 5], Step: [ 700/ 600], Loss: 1.1192\n",
            "Epoch: [ 3/ 5], Step: [ 800/ 600], Loss: 0.9992\n",
            "Epoch: [ 3/ 5], Step: [ 900/ 600], Loss: 1.0626\n",
            "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.0520\n",
            "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 0.9529\n",
            "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.0318\n",
            "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.0256\n",
            "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.0334\n",
            "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 0.8509\n",
            "Epoch: [ 4/ 5], Step: [ 700/ 600], Loss: 1.0325\n",
            "Epoch: [ 4/ 5], Step: [ 800/ 600], Loss: 0.8924\n",
            "Epoch: [ 4/ 5], Step: [ 900/ 600], Loss: 0.8849\n",
            "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 0.8600\n",
            "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 0.8683\n",
            "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 0.8177\n",
            "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 0.9252\n",
            "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 0.8970\n",
            "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 0.7249\n",
            "Epoch: [ 5/ 5], Step: [ 700/ 600], Loss: 0.7104\n",
            "Epoch: [ 5/ 5], Step: [ 800/ 600], Loss: 0.8637\n",
            "Epoch: [ 5/ 5], Step: [ 900/ 600], Loss: 0.9486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we shall be testing out the model by using the following code."
      ],
      "metadata": {
        "id": "BtJcaPsL3B07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the Model\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.view(-1, 28 * 28))\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print('Accuracy of the model on the 10000 test images: % d %%' % (\n",
        "            100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNUJbxOE2Z-y",
        "outputId": "539f8f8d-30c6-4293-93a3-a701c5420eb2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images:  84 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming that you performed all steps correctly, you will get an accuracy of 82%, which is far off from today’s state-of-the-art model, which uses a special type of neural network architecture. For your reference, you can find the entire code for this article below:"
      ],
      "metadata": {
        "id": "EWh6pLzk3_Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# MNIST Dataset (Images and Labels)\n",
        "train_dataset = dsets.MNIST(root ='./data',\n",
        "                            train = True,\n",
        "                            transform = transforms.ToTensor(),\n",
        "                            download = True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root ='./data',\n",
        "                        train = False,\n",
        "                        transform = transforms.ToTensor())\n",
        "\n",
        "# Dataset Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                        batch_size = batch_size,\n",
        "                                        shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                        batch_size = batch_size,\n",
        "                                        shuffle = False)\n",
        "\n",
        "# Hyper Parameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "model = LogisticRegression(input_size, num_classes)\n",
        "\n",
        "# Loss and Optimizer\n",
        "# Softmax is internally computed.\n",
        "# Set parameters to be updated.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# Training the Model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = Variable(images.view(-1, 28 * 28))\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
        "                % (epoch + 1, num_epochs, i + 1,\n",
        "                    len(train_dataset) // batch_size, loss.item()))\n",
        "\n",
        "# Test the Model\n",
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.view(-1, 28 * 28))\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print('Accuracy of the model on the 10000 test images: % d %%' % (\n",
        "            100 * correct / total))\n",
        "\n",
        "# This code is modified by Susobhan Akhuli\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIiGjTd031Jx",
        "outputId": "f104ee9f-c4a7-42ac-f366-6549bb2ff307"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 2.2473\n",
            "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 2.1254\n",
            "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 2.0471\n",
            "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 1.9352\n",
            "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 1.8648\n",
            "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 1.8387\n",
            "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.7232\n",
            "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 1.6575\n",
            "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 1.6445\n",
            "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 1.6038\n",
            "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 1.5405\n",
            "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 1.4685\n",
            "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 1.3504\n",
            "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 1.3040\n",
            "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 1.3221\n",
            "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 1.2667\n",
            "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 1.3292\n",
            "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 1.2298\n",
            "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.1828\n",
            "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 1.1985\n",
            "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 1.0834\n",
            "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 1.1946\n",
            "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 1.1071\n",
            "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 1.1641\n",
            "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 1.0196\n",
            "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 1.0893\n",
            "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 1.0602\n",
            "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 1.1174\n",
            "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 1.0324\n",
            "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 1.1702\n",
            "Accuracy of the model on the 10000 test images:  82 %\n"
          ]
        }
      ]
    }
  ]
}